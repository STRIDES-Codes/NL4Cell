{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "NL4Cell_Encode.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ed7bb53"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import skimage.filters as filters\n",
        "from functools import partial, lru_cache\n",
        "from typing import Union\n",
        "from pprint import pprint\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.mixture import GaussianMixture"
      ],
      "id": "9ed7bb53",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_rWgFxfytuM"
      },
      "source": [
        "import os, re, math\n",
        "import h5py"
      ],
      "id": "h_rWgFxfytuM",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7FIkMULy0M_",
        "outputId": "4618a4ab-cca1-4070-d15b-eb061d8919ae"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "id": "v7FIkMULy0M_",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "a911da13",
        "outputId": "0058e866-d7d5-4a78-8e98-ad2302affccc"
      },
      "source": [
        "#sample_data = pd.read_pickle(\"./data/sample_sc_data.pkl\")\n",
        "sample_data = pd.read_hdf(\"/content/drive/MyDrive/immunolinguistics/frames/ZZZU.h5\", start=499608-1000, stop=499608)\n",
        "sample_data.head(n=10)"
      ],
      "id": "a911da13",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CD123</th>\n",
              "      <th>CD14</th>\n",
              "      <th>CD11c</th>\n",
              "      <th>MHCII</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>498608</th>\n",
              "      <td>-0.819428</td>\n",
              "      <td>0.599702</td>\n",
              "      <td>0.076553</td>\n",
              "      <td>1.103783</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498609</th>\n",
              "      <td>0.718618</td>\n",
              "      <td>0.115962</td>\n",
              "      <td>1.027351</td>\n",
              "      <td>0.263494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498610</th>\n",
              "      <td>-0.157862</td>\n",
              "      <td>-0.576694</td>\n",
              "      <td>-0.376348</td>\n",
              "      <td>-0.093487</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498611</th>\n",
              "      <td>0.285110</td>\n",
              "      <td>-1.159225</td>\n",
              "      <td>-0.029846</td>\n",
              "      <td>-0.125228</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498612</th>\n",
              "      <td>-0.157862</td>\n",
              "      <td>-0.831927</td>\n",
              "      <td>0.014004</td>\n",
              "      <td>-0.173780</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498613</th>\n",
              "      <td>-0.465809</td>\n",
              "      <td>-0.675357</td>\n",
              "      <td>0.621934</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498614</th>\n",
              "      <td>-7.088847</td>\n",
              "      <td>-5.474100</td>\n",
              "      <td>-0.237629</td>\n",
              "      <td>-2.562109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498615</th>\n",
              "      <td>0.813498</td>\n",
              "      <td>-0.046108</td>\n",
              "      <td>0.923564</td>\n",
              "      <td>0.092588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498616</th>\n",
              "      <td>0.092118</td>\n",
              "      <td>-0.095462</td>\n",
              "      <td>-1.048623</td>\n",
              "      <td>-0.326603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498617</th>\n",
              "      <td>-5.074555</td>\n",
              "      <td>-1.392902</td>\n",
              "      <td>-0.536434</td>\n",
              "      <td>-2.055866</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           CD123      CD14     CD11c     MHCII\n",
              "498608 -0.819428  0.599702  0.076553  1.103783\n",
              "498609  0.718618  0.115962  1.027351  0.263494\n",
              "498610 -0.157862 -0.576694 -0.376348 -0.093487\n",
              "498611  0.285110 -1.159225 -0.029846 -0.125228\n",
              "498612 -0.157862 -0.831927  0.014004 -0.173780\n",
              "498613 -0.465809 -0.675357  0.621934  0.000000\n",
              "498614 -7.088847 -5.474100 -0.237629 -2.562109\n",
              "498615  0.813498 -0.046108  0.923564  0.092588\n",
              "498616  0.092118 -0.095462 -1.048623 -0.326603\n",
              "498617 -5.074555 -1.392902 -0.536434 -2.055866"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2df0b6b2"
      },
      "source": [
        "# Binary Encodoing\n",
        "This strategy uses Otsu's thresholding to define + and - for each cell based on the maximum in-class homogeneity. The input is a matrix of $num\\_obs \\times num\\_features$"
      ],
      "id": "2df0b6b2"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cd9f24d"
      },
      "source": [
        "def threshold_val(value, threshold):\n",
        "    return 0 if value <= threshold else 1    \n",
        "    \n",
        "def remove_outliers(x, percentiles=[5, 95]):\n",
        "    a = np.array(x)\n",
        "    upper_percentile = np.percentile(a, percentiles[1])\n",
        "    lower_percentile = np.percentile(a, percentiles[0])\n",
        "    mask = np.logical_and(a < upper_percentile, a > lower_percentile)\n",
        "    return a[mask]\n",
        "\n",
        "    \n",
        "    \n",
        "def vocab_generator(df: pd.DataFrame, style='discrete'):\n",
        "    \"\"\"\n",
        "    For every gene, generate a 'word' that is the ambiguous gene (e.g. \"CD45\"), \n",
        "    the positive, and the negative genes (e.g. \"CD45+\" and \"CD45-\"). \n",
        "    \n",
        "    The \"style\" parameter is meant to let this be expandable further on.\n",
        "    \n",
        "    :param df: The data frame containing the `obs x genes` matrix\n",
        "    :param style: the style of vocab to generate. Options:\n",
        "    :yield: the ambiguous, negative, and positive versions of that gene.  \n",
        "    \"\"\"\n",
        "    \n",
        "    \n",
        "    if style.upper() == 'DISCRETE':\n",
        "        for val in iter(df.columns):\n",
        "            val = val.strip().lower()\n",
        "            yield val, val + \"-\", val + \"+\"\n",
        "                    \n",
        "def generate_vocabulary(df, style='discrete'):\n",
        "    generator = vocab_generator(df=df, style=style)\n",
        "    vocab = [\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"]\n",
        "    if style.upper() == 'DISCRETE':\n",
        "        for tup in generator:\n",
        "            [vocab.append(v) for v in tup]\n",
        "    return vocab\n",
        "    \n",
        "def binary_encode(df, method='otsu', histogram_bins=1000, clip_data=False):\n",
        "    \"\"\"\n",
        "    :param df: Data frame with one row per cell and one column per gene.\n",
        "    :returns: Encoded table-- a copy of df with each numeric entry replaced with 1 for + and 0 for -\n",
        "    :returns: Vocabulary-- a comprehensive vocabulary of each gene in the table\n",
        "    :returns: Gene thresholds-- a dictionary relating {Gene: threshold}\n",
        "    \"\"\"\n",
        "    gene_thresh_dict = {}\n",
        "    encoded_table = pd.DataFrame(0, index=df.index, columns=df.columns)\n",
        "    \n",
        "    # Go through each columns and \n",
        "    # TODO: subsample to avoid loading 1 billion cells at once\n",
        "    for (col_name, col_data) in df.iteritems():\n",
        "        \n",
        "        # Remove outliers from data if parameter is passed (makes more of a difference in Otsu's method)\n",
        "        if clip_data:\n",
        "            data_values = remove_outliers(col_data.values)\n",
        "        else:\n",
        "            data_values = col_data.values\n",
        "        \n",
        "        # Determine threshold based on method passed.\n",
        "        if method.upper() == \"OTSU\":\n",
        "            thresh = filters.threshold_otsu(data_values, nbins=histogram_bins)\n",
        "        elif method.upper() == \"MEDIAN\":\n",
        "            thresh = np.median(data_values)\n",
        "        else:\n",
        "            raise ValueError(\"Unexpected value for parameter `method`: %s\" % method)\n",
        "            \n",
        "        # Set value in threhsold disctionary, encode table.\n",
        "        gene_thresh_dict[col_name] = thresh\n",
        "        threshold_partial = partial(threshold_val, threshold=thresh)\n",
        "        encoded_table.loc[:, col_name] = df.loc[:, col_name].apply(threshold_partial)\n",
        "    \n",
        "    vocab = generate_vocabulary(df, style='discrete')\n",
        "    \n",
        "    return encoded_table, gene_thresh_dict, vocab\n",
        "        \n",
        "        "
      ],
      "id": "9cd9f24d",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "355fcbd4",
        "outputId": "7c0bd1f1-2570-4081-93d7-9c02514c4aa0"
      },
      "source": [
        "encoded_table_otsu, thresh_dict_otsu, vocabulary_otsu = binary_encode(sample_data, method='otsu')\n",
        "encoded_table_median, thresh_dict_median, vocabulary_median = binary_encode(sample_data, method='median')\n",
        "\n",
        "print()"
      ],
      "id": "355fcbd4",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92fde8f5"
      },
      "source": [
        "def write_vocabulary_file(fp, vocab_list, sort=False):\n",
        "    if sort:\n",
        "        vocab_list = sorted(vocab_list)\n",
        "        \n",
        "    with open(fp, 'w') as output:\n",
        "        for word in vocab_list:\n",
        "            output.write(word + \"\\n\")"
      ],
      "id": "92fde8f5",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aa64973",
        "outputId": "fa28ce03-11ca-409f-9f4c-f95d3ac807fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#!pwd\n",
        "write_vocabulary_file(\"vocab.txt\", vocabulary_otsu)\n",
        "! head vocab.txt"
      ],
      "id": "4aa64973",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[PAD]\n",
            "[UNK]\n",
            "[CLS]\n",
            "[SEP]\n",
            "[MASK]\n",
            "cd123\n",
            "cd123-\n",
            "cd123+\n",
            "cd14\n",
            "cd14-\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5532e82c"
      },
      "source": [
        "@lru_cache(maxsize=1024)\n",
        "def binary_to_text(value, protein_name):\n",
        "    protein_name = protein_name.lower()\n",
        "    return protein_name + \"+\" if value == 1 else protein_name + \"-\"\n",
        "    \n",
        "def binary_table_to_text(df):\n",
        "    text_table = pd.DataFrame(0, index=df.index, columns=df.columns)\n",
        "    for col in df.columns:\n",
        "        bin2text_partial = partial(binary_to_text, protein_name=col)\n",
        "        text_table.loc[:, col] = df.loc[:, col].apply(bin2text_partial)\n",
        "    return text_table\n",
        "    "
      ],
      "id": "5532e82c",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "6d35e65d",
        "outputId": "67aa0686-f341-4f6f-99df-66eb3fdf3bf3"
      },
      "source": [
        "encoded_table_otsu"
      ],
      "id": "6d35e65d",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CD123</th>\n",
              "      <th>CD14</th>\n",
              "      <th>CD11c</th>\n",
              "      <th>MHCII</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>498608</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498609</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498610</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498611</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498612</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499603</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499604</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499605</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499606</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499607</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        CD123  CD14  CD11c  MHCII\n",
              "498608      1     1      1      1\n",
              "498609      1     1      1      1\n",
              "498610      1     1      1      1\n",
              "498611      1     1      1      1\n",
              "498612      1     1      1      1\n",
              "...       ...   ...    ...    ...\n",
              "499603      1     1      1      1\n",
              "499604      1     1      1      1\n",
              "499605      1     1      1      1\n",
              "499606      1     1      1      1\n",
              "499607      1     0      0      1\n",
              "\n",
              "[1000 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "0f98d385",
        "outputId": "c7924a03-2e8a-4c4f-c48c-5a4f9556a9a9"
      },
      "source": [
        "binary_table_to_text(encoded_table_otsu)"
      ],
      "id": "0f98d385",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CD123</th>\n",
              "      <th>CD14</th>\n",
              "      <th>CD11c</th>\n",
              "      <th>MHCII</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>498608</th>\n",
              "      <td>cd123+</td>\n",
              "      <td>cd14+</td>\n",
              "      <td>cd11c+</td>\n",
              "      <td>mhcii+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498609</th>\n",
              "      <td>cd123+</td>\n",
              "      <td>cd14+</td>\n",
              "      <td>cd11c+</td>\n",
              "      <td>mhcii+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498610</th>\n",
              "      <td>cd123+</td>\n",
              "      <td>cd14+</td>\n",
              "      <td>cd11c+</td>\n",
              "      <td>mhcii+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498611</th>\n",
              "      <td>cd123+</td>\n",
              "      <td>cd14+</td>\n",
              "      <td>cd11c+</td>\n",
              "      <td>mhcii+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498612</th>\n",
              "      <td>cd123+</td>\n",
              "      <td>cd14+</td>\n",
              "      <td>cd11c+</td>\n",
              "      <td>mhcii+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499603</th>\n",
              "      <td>cd123+</td>\n",
              "      <td>cd14+</td>\n",
              "      <td>cd11c+</td>\n",
              "      <td>mhcii+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499604</th>\n",
              "      <td>cd123+</td>\n",
              "      <td>cd14+</td>\n",
              "      <td>cd11c+</td>\n",
              "      <td>mhcii+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499605</th>\n",
              "      <td>cd123+</td>\n",
              "      <td>cd14+</td>\n",
              "      <td>cd11c+</td>\n",
              "      <td>mhcii+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499606</th>\n",
              "      <td>cd123+</td>\n",
              "      <td>cd14+</td>\n",
              "      <td>cd11c+</td>\n",
              "      <td>mhcii+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499607</th>\n",
              "      <td>cd123+</td>\n",
              "      <td>cd14-</td>\n",
              "      <td>cd11c-</td>\n",
              "      <td>mhcii+</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         CD123   CD14   CD11c   MHCII\n",
              "498608  cd123+  cd14+  cd11c+  mhcii+\n",
              "498609  cd123+  cd14+  cd11c+  mhcii+\n",
              "498610  cd123+  cd14+  cd11c+  mhcii+\n",
              "498611  cd123+  cd14+  cd11c+  mhcii+\n",
              "498612  cd123+  cd14+  cd11c+  mhcii+\n",
              "...        ...    ...     ...     ...\n",
              "499603  cd123+  cd14+  cd11c+  mhcii+\n",
              "499604  cd123+  cd14+  cd11c+  mhcii+\n",
              "499605  cd123+  cd14+  cd11c+  mhcii+\n",
              "499606  cd123+  cd14+  cd11c+  mhcii+\n",
              "499607  cd123+  cd14-  cd11c-  mhcii+\n",
              "\n",
              "[1000 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdcfbf90"
      },
      "source": [
        "def create_names(name, n_grades):\n",
        "    \"\"\"\n",
        "    Given a protein number and the number of grades, return a list of [protein::grade]\n",
        "    Example:\n",
        "    >>> create_names(\"CD45\", 4)\n",
        "    [\"CD45::0\", \"CD45::1\", \"CD45::2\", \"CD45::3\"]\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    grades = [name + \"::\" + str(grade) for grade in range(n_grades)]\n",
        "    return grades\n",
        "        \n",
        "\n",
        "def graded_encode(df, n_comps=3, n_samples=-1, method='gmm'):\n",
        "    \"\"\"\n",
        "    Gaussian Mixture Model\n",
        "    Kmeans\n",
        "    Quantiles = [25, 50, 75]\n",
        "    \"\"\"\n",
        "    \n",
        "    gene_thresh_dict = {}\n",
        "    encoded_table = pd.DataFrame(0, index=df.index, columns=df.columns)\n",
        "\n",
        "    \n",
        "    for (col_name, col_data) in df.iteritems():\n",
        "        reshaped_data = col_data.values.reshape(-1, 1)\n",
        "        gmm = GaussianMixture(n_components=n_comps, covariance_type='full', verbose=0)\n",
        "        preds = gmm.fit_predict(reshaped_data)\n",
        "        grades = create_names(col_name, n_comps)\n",
        "        \n",
        "        # Find the indices for sorting the models in increasing order (min expr to max expr)\n",
        "        original_idxs = np.arange(n_comps)\n",
        "        sorted_idxs = np.argsort(gmm.means_.ravel())\n",
        "        \n",
        "      \n",
        "        # This is a swap dictionary relating the mean to the sorted position (i.e. grade)\n",
        "        swap_dict = {original: new for original, new in zip(original_idxs.ravel(), sorted_idxs.ravel())}\n",
        "        \n",
        "        graded_genes = []\n",
        "        for i in preds:\n",
        "            graded_genes.append(swap_dict[i])\n",
        "            \n",
        "        #graded_genes = np.vectorize(swap_dict.get)(preds)\n",
        "        #print(graded_genes)\n",
        "        encoded_table.loc[:, col_name] = np.asarray(graded_genes)\n",
        "        \n",
        "        \n",
        "    return encoded_table\n",
        "    "
      ],
      "id": "cdcfbf90",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "2cf5a51b"
      },
      "source": [
        "graded_table = graded_encode(sample_data)"
      ],
      "id": "2cf5a51b",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ebf0dc4"
      },
      "source": [
        "@lru_cache(maxsize=1024)\n",
        "def graded_to_text(value, protein_name):\n",
        "    return protein_name + \"::\" + str(value)\n",
        "    \n",
        "def graded_table_to_text(df):\n",
        "    text_table = pd.DataFrame(0, index=df.index, columns=df.columns, dtype=str)\n",
        "    for col in df.columns:\n",
        "        graded2text_partial = partial(graded_to_text, protein_name=col)\n",
        "        text_table.loc[:, col] = df.loc[:, col].apply(graded2text_partial)\n",
        "    return text_table\n",
        "    \n",
        "    "
      ],
      "id": "5ebf0dc4",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "1ffe3710",
        "outputId": "87214da9-e8d2-4b81-be1a-45fa53bb067e"
      },
      "source": [
        "sample_data.head()"
      ],
      "id": "1ffe3710",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CD123</th>\n",
              "      <th>CD14</th>\n",
              "      <th>CD11c</th>\n",
              "      <th>MHCII</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>498608</th>\n",
              "      <td>-0.819428</td>\n",
              "      <td>0.599702</td>\n",
              "      <td>0.076553</td>\n",
              "      <td>1.103783</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498609</th>\n",
              "      <td>0.718618</td>\n",
              "      <td>0.115962</td>\n",
              "      <td>1.027351</td>\n",
              "      <td>0.263494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498610</th>\n",
              "      <td>-0.157862</td>\n",
              "      <td>-0.576694</td>\n",
              "      <td>-0.376348</td>\n",
              "      <td>-0.093487</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498611</th>\n",
              "      <td>0.285110</td>\n",
              "      <td>-1.159225</td>\n",
              "      <td>-0.029846</td>\n",
              "      <td>-0.125228</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498612</th>\n",
              "      <td>-0.157862</td>\n",
              "      <td>-0.831927</td>\n",
              "      <td>0.014004</td>\n",
              "      <td>-0.173780</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           CD123      CD14     CD11c     MHCII\n",
              "498608 -0.819428  0.599702  0.076553  1.103783\n",
              "498609  0.718618  0.115962  1.027351  0.263494\n",
              "498610 -0.157862 -0.576694 -0.376348 -0.093487\n",
              "498611  0.285110 -1.159225 -0.029846 -0.125228\n",
              "498612 -0.157862 -0.831927  0.014004 -0.173780"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "5817c40e",
        "outputId": "cbfef39b-9e20-4cc4-917e-5a21b510abd2"
      },
      "source": [
        "graded_table.head()"
      ],
      "id": "5817c40e",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CD123</th>\n",
              "      <th>CD14</th>\n",
              "      <th>CD11c</th>\n",
              "      <th>MHCII</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>498608</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498609</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498610</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498611</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498612</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        CD123  CD14  CD11c  MHCII\n",
              "498608      1     1      2      2\n",
              "498609      1     1      0      1\n",
              "498610      1     1      2      1\n",
              "498611      1     0      2      1\n",
              "498612      1     0      2      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "54c9aca1",
        "outputId": "cc542537-2480-43a2-c914-58f9c2d53de6"
      },
      "source": [
        "graded_table_to_text(graded_table.head())"
      ],
      "id": "54c9aca1",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CD123</th>\n",
              "      <th>CD14</th>\n",
              "      <th>CD11c</th>\n",
              "      <th>MHCII</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>498608</th>\n",
              "      <td>CD123::1</td>\n",
              "      <td>CD14::1</td>\n",
              "      <td>CD11c::2</td>\n",
              "      <td>MHCII::2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498609</th>\n",
              "      <td>CD123::1</td>\n",
              "      <td>CD14::1</td>\n",
              "      <td>CD11c::0</td>\n",
              "      <td>MHCII::1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498610</th>\n",
              "      <td>CD123::1</td>\n",
              "      <td>CD14::1</td>\n",
              "      <td>CD11c::2</td>\n",
              "      <td>MHCII::1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498611</th>\n",
              "      <td>CD123::1</td>\n",
              "      <td>CD14::0</td>\n",
              "      <td>CD11c::2</td>\n",
              "      <td>MHCII::1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498612</th>\n",
              "      <td>CD123::1</td>\n",
              "      <td>CD14::0</td>\n",
              "      <td>CD11c::2</td>\n",
              "      <td>MHCII::1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           CD123     CD14     CD11c     MHCII\n",
              "498608  CD123::1  CD14::1  CD11c::2  MHCII::2\n",
              "498609  CD123::1  CD14::1  CD11c::0  MHCII::1\n",
              "498610  CD123::1  CD14::1  CD11c::2  MHCII::1\n",
              "498611  CD123::1  CD14::0  CD11c::2  MHCII::1\n",
              "498612  CD123::1  CD14::0  CD11c::2  MHCII::1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfb11efc"
      },
      "source": [
        ""
      ],
      "id": "cfb11efc",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "040764ed",
        "outputId": "4e2ab037-5013-4f78-cc5f-ecce2a88318b"
      },
      "source": [
        "output_folder = '/content/drive/MyDrive/immunolinguistics/frames_converted/'\n",
        "#!mkdir /content/drive/MyDrive/immunolinguistics/frames_converted/\n",
        "raw_data_folder = '/content/drive/MyDrive/immunolinguistics/frames/'\n",
        "raw_data_folder = '/content/drive/MyDrive/immunolinguistics/split_frames/smaller/'\n",
        "files = os.listdir(raw_data_folder)\n",
        "files"
      ],
      "id": "040764ed",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Z238_0.pkl',\n",
              " 'Z238_2.pkl',\n",
              " 'Z238_1.pkl',\n",
              " 'Z238_3.pkl',\n",
              " 'Z238_4.pkl',\n",
              " 'Z238_6.pkl',\n",
              " 'Z238_5.pkl',\n",
              " 'Z238_7.pkl',\n",
              " 'Z238_8.pkl',\n",
              " 'Z238_9.pkl',\n",
              " 'Z238_10.pkl',\n",
              " 'Z238_11.pkl',\n",
              " 'Z238_12.pkl']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seJGEUL5zJXa"
      },
      "source": [
        "def converPKL2text(file, data_folder, output_prefix, output_folder, encode_method = \"otsu\", max_lines = int(1e6)):\n",
        "    if(data_folder == output_folder):\n",
        "        print(\"Error: input file folder should not be same as output folder!\\n\")\n",
        "        return(None)\n",
        "    path_to_infile = data_folder + \"/\" + file\n",
        "    print(\"Processing \", path_to_infile, \" with method\", encode_method, \"...\", end = \"\")\n",
        "    if not os.path.isfile(path_to_infile):\n",
        "        return 1\n",
        "\n",
        "    if bool(re.search(\".pkl$\", file)):\n",
        "        data = pd.read_pickle(path_to_infile)\n",
        "        print(\"Data have \", data.shape[0], \" lines\")\n",
        "        na_cnt = data.isnull().sum(axis = 0)\n",
        "        if na_cnt.max() > 0:\n",
        "            print(path_to_infile, \" has some NAs. Skip...\")\n",
        "            print(na_cnt);\n",
        "            return 1;\n",
        "        \n",
        "        if data.shape[0] <= max_lines:\n",
        "            path_to_output_file = output_folder + \"/\" + output_prefix + \".txt.gz\"\n",
        "            path_to_output_voc_file = output_folder + \"/\" + output_prefix + \".voc.txt\"\n",
        "            if os.path.exists(path_to_output_file):\n",
        "               print(\"File \", path_to_output_file, \"exists, skip...\")\n",
        "                #return 1\n",
        "            if encode_method == \"gmm\":\n",
        "                graded_table = graded_encode(data)\n",
        "                text_table = graded_table_to_text(graded_table)\n",
        "                #vocabulary = generate_vocabulary(text_table) ###\n",
        "            else:\n",
        "                encoded_table, thresh_dict, vocabulary = binary_encode(data, method= encode_method)\n",
        "                text_table = binary_table_to_text(encoded_table)\n",
        "            #pd.to_pickle(text_table, path_to_output_file)\n",
        "            write_vocabulary_file(path_to_output_voc_file, vocabulary)  \n",
        "            text_table.to_csv(path_to_output_file, sep=' ', index=True, header=False, compression = \"gzip\") ###\n",
        "        else:\n",
        "            print(\"encoding \", max_lines, \"lines per time\", end = \"\")\n",
        "            for k in range(0, math.ceil(data.shape[0]/max_lines)):\n",
        "                print(k, \"...\", end = \"\");\n",
        "                path_to_output_file = output_folder + \"/\" + output_prefix + \".\" + str(k) + \".txt.gz\"\n",
        "                path_to_output_voc_file = output_folder + \"/\" + output_prefix + \".\" + str(k) + \".voc.txt\"\n",
        "                #if os.path.exists(path_to_output_file):\n",
        "                #  print(\"File \", path_to_output_file, \"exists, skip...\")\n",
        "                #  continue\n",
        "                print(\"\\n output\", path_to_output_file, end = ' ')\n",
        "                start = k * max_lines;\n",
        "                end = (k+1) * max_lines;\n",
        "                if(end > data.shape[0] or data.shape[0] - end < max_lines/2):\n",
        "                    end = data.shape[0]\n",
        "                print(\" start:\", start, \"end:\", end, end = \"\\n\")\n",
        "                sub_data = data.iloc[start:end,]\n",
        "                if encode_method == \"gmm\":\n",
        "                   graded_table = graded_encode(sub_data)\n",
        "                   text_table = graded_table_to_text(graded_table)\n",
        "                else:\n",
        "                   encoded_table, thresh_dict, vocabulary = binary_encode(sub_data, method= encode_method)\n",
        "                   text_table = binary_table_to_text(encoded_table)\n",
        "                #pd.to_pickle(text_table, path_to_output_file) \n",
        "                write_vocabulary_file(path_to_output_voc_file, vocabulary)\n",
        "                text_table.to_csv(path_to_output_file, sep=' ', index=True, header=False, compression = \"gzip\") ###    \n",
        "                if end >= data.shape[0]:\n",
        "                    return 1\n",
        "    elif bool(re.search(\".hd5$\", file)):\n",
        "        print(\"skip hd5 files now...\")\n",
        "        return 1\n",
        "        k = 0\n",
        "        while 1:\n",
        "            data = pd.read_hdf(path_to_infile, start = k*max_lines, stop = (k+1)*max_lines)\n",
        "            k+=1\n",
        "    else:\n",
        "        print(\"Unknown file format, skip...\\n\")\n",
        "        return 1\n",
        "    print(\" ... finished!\\n\")\n",
        "    return 1"
      ],
      "id": "seJGEUL5zJXa",
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ybu6DBpKzRZW",
        "outputId": "b7eafb2d-f3cb-4926-9ed9-4a75ec389b97"
      },
      "source": [
        "output_folder = '/content/drive/MyDrive/immunolinguistics/frames_converted/'\n",
        "#!mkdir /content/drive/MyDrive/immunolinguistics/frames_converted/\n",
        "raw_data_folder = '/content/drive/MyDrive/immunolinguistics/frames/'\n",
        "#raw_data_folder = '/content/drive/MyDrive/immunolinguistics/split_frames'\n",
        "files = os.listdir(raw_data_folder)\n",
        "files\n",
        "\n",
        "#for file in files:\n",
        "#files = ['Z2ZJ.pkl']\n",
        "for i in files:\n",
        "  if i == \"Z238.pkl\": continue # file size too large, skip this one. Procee its splitted data.\n",
        "  for m in ['otsu', 'median']:\n",
        "    file_prefix = i.split(\".\")[0]\n",
        "    file_prefix = file_prefix + '-' + m\n",
        "    converPKL2text(i, raw_data_folder, file_prefix, output_folder, encode_method= m)"
      ],
      "id": "Ybu6DBpKzRZW",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing  /content/drive/MyDrive/immunolinguistics/frames//Z2L2.pkl  with method otsu ...Data have  8817845  lines\n",
            "encoding  1000000 lines per time0 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z2L2-otsu.0.txt.gz  start: 0 end: 1000000\n",
            "1 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z2L2-otsu.1.txt.gz  start: 1000000 end: 2000000\n",
            "2 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z2L2-otsu.2.txt.gz  start: 2000000 end: 3000000\n",
            "3 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z2L2-otsu.3.txt.gz  start: 3000000 end: 4000000\n",
            "4 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z2L2-otsu.4.txt.gz  start: 4000000 end: 5000000\n",
            "5 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z2L2-otsu.5.txt.gz  start: 5000000 end: 6000000\n",
            "6 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z2L2-otsu.6.txt.gz  start: 6000000 end: 7000000\n",
            "7 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z2L2-otsu.7.txt.gz  start: 7000000 end: 8000000\n",
            "8 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z2L2-otsu.8.txt.gz  start: 8000000 end: 8817845\n",
            "Processing  /content/drive/MyDrive/immunolinguistics/frames//Z2L2.pkl  with method median ...Data have  8817845  lines\n",
            "encoding  1000000 lines per time0 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z2L2-median.0.txt.gz  start: 0 end: 1000000\n",
            "1 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z2L2-median.1.txt.gz  start: 1000000 end: 2000000\n",
            "2 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z2L2-median.2.txt.gz  start: 2000000 end: 3000000\n",
            "3 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z2L2-median.3.txt.gz  start: 3000000 end: 4000000\n",
            "4 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z2L2-median.4.txt.gz  start: 4000000 end: 5000000\n",
            "5 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z2L2-median.5.txt.gz  start: 5000000 end: 6000000\n",
            "6 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z2L2-median.6.txt.gz  start: 6000000 end: 7000000\n",
            "7 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z2L2-median.7.txt.gz  start: 7000000 end: 8000000\n",
            "8 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z2L2-median.8.txt.gz  start: 8000000 end: 8817845\n",
            "Processing  /content/drive/MyDrive/immunolinguistics/frames//Z2ZJ.pkl  with method otsu ...Data have  739606  lines\n",
            " ... finished!\n",
            "\n",
            "Processing  /content/drive/MyDrive/immunolinguistics/frames//Z2ZJ.pkl  with method median ...Data have  739606  lines\n",
            " ... finished!\n",
            "\n",
            "Processing  /content/drive/MyDrive/immunolinguistics/frames//Z367.pkl  with method otsu ...Data have  11528729  lines\n",
            "encoding  1000000 lines per time0 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z367-otsu.0.txt.gz  start: 0 end: 1000000\n",
            "1 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z367-otsu.1.txt.gz  start: 1000000 end: 2000000\n",
            "2 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z367-otsu.2.txt.gz  start: 2000000 end: 3000000\n",
            "3 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z367-otsu.3.txt.gz  start: 3000000 end: 4000000\n",
            "4 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z367-otsu.4.txt.gz  start: 4000000 end: 5000000\n",
            "5 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z367-otsu.5.txt.gz  start: 5000000 end: 6000000\n",
            "6 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z367-otsu.6.txt.gz  start: 6000000 end: 7000000\n",
            "7 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z367-otsu.7.txt.gz  start: 7000000 end: 8000000\n",
            "8 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z367-otsu.8.txt.gz  start: 8000000 end: 9000000\n",
            "9 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z367-otsu.9.txt.gz  start: 9000000 end: 10000000\n",
            "10 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z367-otsu.10.txt.gz  start: 10000000 end: 11000000\n",
            "11 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z367-otsu.11.txt.gz  start: 11000000 end: 11528729\n",
            "Processing  /content/drive/MyDrive/immunolinguistics/frames//Z367.pkl  with method median ...Data have  11528729  lines\n",
            "encoding  1000000 lines per time0 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z367-median.0.txt.gz  start: 0 end: 1000000\n",
            "1 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z367-median.1.txt.gz  start: 1000000 end: 2000000\n",
            "2 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z367-median.2.txt.gz  start: 2000000 end: 3000000\n",
            "3 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z367-median.3.txt.gz  start: 3000000 end: 4000000\n",
            "4 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z367-median.4.txt.gz  start: 4000000 end: 5000000\n",
            "5 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z367-median.5.txt.gz  start: 5000000 end: 6000000\n",
            "6 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z367-median.6.txt.gz  start: 6000000 end: 7000000\n",
            "7 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z367-median.7.txt.gz  start: 7000000 end: 8000000\n",
            "8 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z367-median.8.txt.gz  start: 8000000 end: 9000000\n",
            "9 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z367-median.9.txt.gz  start: 9000000 end: 10000000\n",
            "10 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z367-median.10.txt.gz  start: 10000000 end: 11000000\n",
            "11 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z367-median.11.txt.gz  start: 11000000 end: 11528729\n",
            "Processing  /content/drive/MyDrive/immunolinguistics/frames//ZZBG.pkl  with method otsu ...Data have  4212900  lines\n",
            "/content/drive/MyDrive/immunolinguistics/frames//ZZBG.pkl  has some NAs. Skip...\n",
            "CD95            0\n",
            "CD27      1049609\n",
            "CD3       3163291\n",
            "CD4             0\n",
            "CD45RA          0\n",
            "CD25            0\n",
            "CD8             0\n",
            "dtype: int64\n",
            "Processing  /content/drive/MyDrive/immunolinguistics/frames//ZZBG.pkl  with method median ...Data have  4212900  lines\n",
            "/content/drive/MyDrive/immunolinguistics/frames//ZZBG.pkl  has some NAs. Skip...\n",
            "CD95            0\n",
            "CD27      1049609\n",
            "CD3       3163291\n",
            "CD4             0\n",
            "CD45RA          0\n",
            "CD25            0\n",
            "CD8             0\n",
            "dtype: int64\n",
            "Processing  /content/drive/MyDrive/immunolinguistics/frames//ZZD7.pkl  with method otsu ...Data have  49575830  lines\n",
            "/content/drive/MyDrive/immunolinguistics/frames//ZZD7.pkl  has some NAs. Skip...\n",
            "CD4              0\n",
            "CD3              0\n",
            "CD45RO    26420845\n",
            "dtype: int64\n",
            "Processing  /content/drive/MyDrive/immunolinguistics/frames//ZZD7.pkl  with method median ...Data have  49575830  lines\n",
            "/content/drive/MyDrive/immunolinguistics/frames//ZZD7.pkl  has some NAs. Skip...\n",
            "CD4              0\n",
            "CD3              0\n",
            "CD45RO    26420845\n",
            "dtype: int64\n",
            "Processing  /content/drive/MyDrive/immunolinguistics/frames//ZZYA.h5  with method otsu ...Unknown file format, skip...\n",
            "\n",
            "Processing  /content/drive/MyDrive/immunolinguistics/frames//ZZYA.h5  with method median ...Unknown file format, skip...\n",
            "\n",
            "Processing  /content/drive/MyDrive/immunolinguistics/frames//ZZZU.h5  with method otsu ...Unknown file format, skip...\n",
            "\n",
            "Processing  /content/drive/MyDrive/immunolinguistics/frames//ZZZU.h5  with method median ...Unknown file format, skip...\n",
            "\n",
            "Processing  /content/drive/MyDrive/immunolinguistics/frames//Z3YR.pkl  with method otsu ...Data have  23733709  lines\n",
            "encoding  1000000 lines per time0 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z3YR-otsu.0.txt.gz  start: 0 end: 1000000\n",
            "1 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z3YR-otsu.1.txt.gz  start: 1000000 end: 2000000\n",
            "2 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z3YR-otsu.2.txt.gz  start: 2000000 end: 3000000\n",
            "3 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z3YR-otsu.3.txt.gz  start: 3000000 end: 4000000\n",
            "4 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z3YR-otsu.4.txt.gz  start: 4000000 end: 5000000\n",
            "5 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z3YR-otsu.5.txt.gz  start: 5000000 end: 6000000\n",
            "6 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z3YR-otsu.6.txt.gz  start: 6000000 end: 7000000\n",
            "7 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z3YR-otsu.7.txt.gz  start: 7000000 end: 8000000\n",
            "8 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z3YR-otsu.8.txt.gz  start: 8000000 end: 9000000\n",
            "9 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z3YR-otsu.9.txt.gz  start: 9000000 end: 10000000\n",
            "10 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z3YR-otsu.10.txt.gz  start: 10000000 end: 11000000\n",
            "11 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z3YR-otsu.11.txt.gz  start: 11000000 end: 12000000\n",
            "12 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z3YR-otsu.12.txt.gz  start: 12000000 end: 13000000\n",
            "13 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z3YR-otsu.13.txt.gz  start: 13000000 end: 14000000\n",
            "14 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z3YR-otsu.14.txt.gz  start: 14000000 end: 15000000\n",
            "15 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z3YR-otsu.15.txt.gz  start: 15000000 end: 16000000\n",
            "16 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z3YR-otsu.16.txt.gz  start: 16000000 end: 17000000\n",
            "17 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z3YR-otsu.17.txt.gz  start: 17000000 end: 18000000\n",
            "18 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z3YR-otsu.18.txt.gz  start: 18000000 end: 19000000\n",
            "19 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z3YR-otsu.19.txt.gz  start: 19000000 end: 20000000\n",
            "20 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z3YR-otsu.20.txt.gz  start: 20000000 end: 21000000\n",
            "21 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z3YR-otsu.21.txt.gz  start: 21000000 end: 22000000\n",
            "22 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z3YR-otsu.22.txt.gz  start: 22000000 end: 23000000\n",
            "23 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z3YR-otsu.23.txt.gz  start: 23000000 end: 23733709\n",
            "Processing  /content/drive/MyDrive/immunolinguistics/frames//Z3YR.pkl  with method median ...Data have  23733709  lines\n",
            "encoding  1000000 lines per time0 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z3YR-median.0.txt.gz  start: 0 end: 1000000\n",
            "1 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z3YR-median.1.txt.gz  start: 1000000 end: 2000000\n",
            "2 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z3YR-median.2.txt.gz  start: 2000000 end: 3000000\n",
            "3 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z3YR-median.3.txt.gz  start: 3000000 end: 4000000\n",
            "4 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z3YR-median.4.txt.gz  start: 4000000 end: 5000000\n",
            "5 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z3YR-median.5.txt.gz  start: 5000000 end: 6000000\n",
            "6 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z3YR-median.6.txt.gz  start: 6000000 end: 7000000\n",
            "7 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z3YR-median.7.txt.gz  start: 7000000 end: 8000000\n",
            "8 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z3YR-median.8.txt.gz  start: 8000000 end: 9000000\n",
            "9 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z3YR-median.9.txt.gz  start: 9000000 end: 10000000\n",
            "10 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z3YR-median.10.txt.gz  start: 10000000 end: 11000000\n",
            "11 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z3YR-median.11.txt.gz  start: 11000000 end: 12000000\n",
            "12 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z3YR-median.12.txt.gz  start: 12000000 end: 13000000\n",
            "13 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z3YR-median.13.txt.gz  start: 13000000 end: 14000000\n",
            "14 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z3YR-median.14.txt.gz  start: 14000000 end: 15000000\n",
            "15 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z3YR-median.15.txt.gz  start: 15000000 end: 16000000\n",
            "16 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z3YR-median.16.txt.gz  start: 16000000 end: 17000000\n",
            "17 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z3YR-median.17.txt.gz  start: 17000000 end: 18000000\n",
            "18 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z3YR-median.18.txt.gz  start: 18000000 end: 19000000\n",
            "19 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z3YR-median.19.txt.gz  start: 19000000 end: 20000000\n",
            "20 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z3YR-median.20.txt.gz  start: 20000000 end: 21000000\n",
            "21 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z3YR-median.21.txt.gz  start: 21000000 end: 22000000\n",
            "22 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z3YR-median.22.txt.gz  start: 22000000 end: 23000000\n",
            "23 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z3YR-median.23.txt.gz  start: 23000000 end: 23733709\n",
            "Processing  /content/drive/MyDrive/immunolinguistics/frames//Z23S.pkl  with method otsu ...Data have  17063682  lines\n",
            "encoding  1000000 lines per time0 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z23S-otsu.0.txt.gz  start: 0 end: 1000000\n",
            "1 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z23S-otsu.1.txt.gz  start: 1000000 end: 2000000\n",
            "2 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z23S-otsu.2.txt.gz  start: 2000000 end: 3000000\n",
            "3 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z23S-otsu.3.txt.gz  start: 3000000 end: 4000000\n",
            "4 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z23S-otsu.4.txt.gz  start: 4000000 end: 5000000\n",
            "5 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z23S-otsu.5.txt.gz  start: 5000000 end: 6000000\n",
            "6 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z23S-otsu.6.txt.gz  start: 6000000 end: 7000000\n",
            "7 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z23S-otsu.7.txt.gz  start: 7000000 end: 8000000\n",
            "8 ...\n",
            " output /content/drive/MyDrive/immunolinguistics/frames_converted//Z23S-otsu.8.txt.gz  start: 8000000 end: 9000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKJIxggkzTwh"
      },
      "source": [
        "output_folder = '/content/drive/MyDrive/immunolinguistics/frames_converted/'\n",
        "#!mkdir /content/drive/MyDrive/immunolinguistics/frames_converted/\n",
        "#raw_data_folder = '/content/drive/MyDrive/immunolinguistics/frames/'\n",
        "raw_data_folder = '/content/drive/MyDrive/immunolinguistics/split_frames'\n",
        "files = os.listdir(raw_data_folder)\n",
        "files\n",
        "\n",
        "#for file in files:\n",
        "#files = ['Z2ZJ.pkl']\n",
        "for i in files:\n",
        "  #if(i == \"Z238.pkl\"): continue\n",
        "  if i == \"ZZBG.pkl\": continue\n",
        "  for m in ['otsu', 'median']:    \n",
        "    file_prefix = i.split(\".\")[0]\n",
        "    file_prefix = file_prefix + '-' + m\n",
        "    converPKL2text(i, raw_data_folder, file_prefix, output_folder, encode_method= m)"
      ],
      "id": "LKJIxggkzTwh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWpp22Z63GYl",
        "outputId": "9470d34e-ad87-4caf-8d37-61e25d07b424"
      },
      "source": [
        "!gzip -dc /content/drive/MyDrive/immunolinguistics/frames_converted/Z2L2-otsu.0.txt.gz |head"
      ],
      "id": "hWpp22Z63GYl",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 cd45+ hla-dr+ cd27+ cd235+ cd19- cd5- cd38+ cd4+ cd8- cd20- cd16+ cd123- cd56+ cd14+ cd11c+ cd45ra+ cd3- cd66+ cd61+\n",
            "1 cd45- hla-dr+ cd27- cd235+ cd19+ cd5- cd38- cd4- cd8- cd20- cd16- cd123- cd56- cd14- cd11c- cd45ra+ cd3- cd66- cd61-\n",
            "2 cd45+ hla-dr+ cd27- cd235+ cd19+ cd5- cd38- cd4- cd8- cd20- cd16- cd123- cd56- cd14- cd11c- cd45ra+ cd3- cd66+ cd61-\n",
            "3 cd45+ hla-dr+ cd27- cd235- cd19+ cd5- cd38+ cd4- cd8- cd20+ cd16- cd123+ cd56+ cd14- cd11c- cd45ra+ cd3- cd66- cd61-\n",
            "4 cd45+ hla-dr+ cd27+ cd235- cd19- cd5+ cd38+ cd4- cd8- cd20- cd16- cd123- cd56+ cd14- cd11c- cd45ra+ cd3- cd66+ cd61-\n",
            "5 cd45+ hla-dr- cd27+ cd235+ cd19- cd5+ cd38+ cd4- cd8+ cd20- cd16+ cd123- cd56+ cd14- cd11c+ cd45ra+ cd3+ cd66+ cd61+\n",
            "6 cd45+ hla-dr+ cd27+ cd235- cd19+ cd5+ cd38- cd4- cd8- cd20- cd16- cd123- cd56- cd14- cd11c- cd45ra- cd3- cd66+ cd61-\n",
            "7 cd45+ hla-dr- cd27- cd235+ cd19- cd5- cd38+ cd4- cd8- cd20- cd16+ cd123- cd56+ cd14- cd11c+ cd45ra+ cd3- cd66- cd61-\n",
            "8 cd45+ hla-dr+ cd27+ cd235+ cd19+ cd5+ cd38- cd4- cd8- cd20+ cd16+ cd123- cd56+ cd14- cd11c- cd45ra+ cd3- cd66- cd61-\n",
            "9 cd45+ hla-dr+ cd27- cd235- cd19+ cd5- cd38+ cd4- cd8- cd20- cd16- cd123- cd56+ cd14- cd11c- cd45ra+ cd3- cd66- cd61-\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJXP1MSP3RNA"
      },
      "source": [
        "x = pd.read_pickle(\"/content/drive/MyDrive/immunolinguistics/frames/ZZBG.pkl\")"
      ],
      "id": "YJXP1MSP3RNA",
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbkbrfMqXeW0",
        "outputId": "5a29e630-184c-476e-da33-26c8b4c27f9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x.isnull().sum(axis = 0).max() > 0"
      ],
      "id": "cbkbrfMqXeW0",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVZz0V3YXxV0",
        "outputId": "a3a97833-4ed0-45b0-b98d-5bb543151213",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x.shape"
      ],
      "id": "aVZz0V3YXxV0",
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4212900, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYMoAOk1Xyln",
        "outputId": "e54f373d-d4c7-4197-be32-c78cb652d2ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "'CD45+'.lower()"
      ],
      "id": "vYMoAOk1Xyln",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cd45+'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nM3lrEMyi85G",
        "outputId": "0850f853-e3b1-42d0-f8d4-cc3663882452",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x.isnull().sum(axis = 0)"
      ],
      "id": "nM3lrEMyi85G",
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CD95            0\n",
              "CD27      1049609\n",
              "CD3       3163291\n",
              "CD4             0\n",
              "CD45RA          0\n",
              "CD25            0\n",
              "CD8             0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8kNTP2AosVG"
      },
      "source": [
        ""
      ],
      "id": "c8kNTP2AosVG",
      "execution_count": null,
      "outputs": []
    }
  ]
}