{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CellAttention with RoBERTa",
      "provenance": [],
      "authorship_tag": "ABX9TyMmbVcucyUg/ku9exOfZx9N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/STRIDES-Codes/NL4Cell-Integrating-NLP-with-single-cell-data-analysis/blob/main/CellAttention_with_RoBERTa.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJ4LiB_So76e"
      },
      "source": [
        "# All"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGawA05dBnAA"
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WELNTlBBrQe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d14531fe-9cfd-4ee1-e65c-59bf5eacd7a0"
      },
      "source": [
        "# %%capture\n",
        "!pip install git+https://github.com/justinphan3110/transformers.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/justinphan3110/transformers.git\n",
            "  Cloning https://github.com/justinphan3110/transformers.git to /tmp/pip-req-build-uy34wbk1\n",
            "  Running command git clone -q https://github.com/justinphan3110/transformers.git /tmp/pip-req-build-uy34wbk1\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.9.0.dev0) (21.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 7.2 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub==0.0.12\n",
            "  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.9.0.dev0) (3.0.12)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.9.0.dev0) (4.6.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.9.0.dev0) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.9.0.dev0) (4.41.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers==4.9.0.dev0) (3.13)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 61.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.9.0.dev0) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.9.0.dev0) (2019.12.20)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers==4.9.0.dev0) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.9.0.dev0) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.9.0.dev0) (3.5.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.9.0.dev0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.9.0.dev0) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.9.0.dev0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.9.0.dev0) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.9.0.dev0) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.9.0.dev0) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.9.0.dev0) (7.1.2)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.9.0.dev0-py3-none-any.whl size=2534653 sha256=65501d0658c08f09a7ad0859ab2340b073d6374460156294606fc5f3ccfce7b8\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-_1p8ryf5/wheels/18/e4/e5/081c522c96f60fe34d3487499b8415b7c13a42d319b2e4a7af\n",
            "Successfully built transformers\n",
            "Installing collected packages: tokenizers, sacremoses, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.0.12 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.9.0.dev0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0W7MvbTjB2fp"
      },
      "source": [
        "from transformers import EncoderDecoderModel, RobertaTokenizer, RobertaConfig, RobertaModel\n",
        "import torch\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypPLSYBqCTMU",
        "outputId": "ed154a6f-d1b7-47ba-a13d-1c8375133a95"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "  device = torch.device('cuda')\n",
        "  print(torch.cuda.get_device_name())\n",
        "else:\n",
        "  device = torch.device('cpu')\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAa52ldgo-Hj"
      },
      "source": [
        "## Processed Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dJuSxepDEV-",
        "outputId": "c93da0d9-2474-4577-af0d-46cdf1d08371"
      },
      "source": [
        "!gsutil cp gs://cytereader/preprocessed_cell_corpus_test.pkl.zip .\n",
        "!unzip preprocessed_cell_corpus_test.pkl.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://cytereader/preprocessed_cell_corpus_test.pkl.zip...\n",
            "/ [1 files][218.2 MiB/218.2 MiB]                                                \n",
            "Operation completed over 1 objects/218.2 MiB.                                    \n",
            "Archive:  preprocessed_cell_corpus_test.pkl.zip\n",
            "  inflating: preprocessed_cell_corpus_test.pkl  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "zk7V-I_dD-sG",
        "outputId": "b9b8d50f-7872-4890-929a-b54b41973c3f"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "data = np.load('sample_sc_data.pkl', allow_pickle=True)\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CD45</th>\n",
              "      <th>CD196_CCR6</th>\n",
              "      <th>CD181_CXCR1</th>\n",
              "      <th>HLA_DR</th>\n",
              "      <th>CD15</th>\n",
              "      <th>CD31_PECAM1</th>\n",
              "      <th>CD8a</th>\n",
              "      <th>CD182_CXCR2</th>\n",
              "      <th>IgA</th>\n",
              "      <th>CD66ace</th>\n",
              "      <th>CD63</th>\n",
              "      <th>CD14</th>\n",
              "      <th>CD66b</th>\n",
              "      <th>CD62L_Lselectin</th>\n",
              "      <th>CD3</th>\n",
              "      <th>CD27</th>\n",
              "      <th>CD86</th>\n",
              "      <th>CD10</th>\n",
              "      <th>CD197_CCR7</th>\n",
              "      <th>CD28</th>\n",
              "      <th>CD11c</th>\n",
              "      <th>CD33</th>\n",
              "      <th>CD161</th>\n",
              "      <th>CD45RO</th>\n",
              "      <th>CD24</th>\n",
              "      <th>CD38</th>\n",
              "      <th>CD278_ICOS</th>\n",
              "      <th>CD32</th>\n",
              "      <th>CD152_CTLA4</th>\n",
              "      <th>IgM</th>\n",
              "      <th>CD184_CXCR4</th>\n",
              "      <th>CD279_PD1</th>\n",
              "      <th>CD56</th>\n",
              "      <th>CD16</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.279450</td>\n",
              "      <td>-0.707366</td>\n",
              "      <td>0.384317</td>\n",
              "      <td>0.836923</td>\n",
              "      <td>1.096945</td>\n",
              "      <td>0.228808</td>\n",
              "      <td>-0.096544</td>\n",
              "      <td>0.767240</td>\n",
              "      <td>0.820186</td>\n",
              "      <td>0.665852</td>\n",
              "      <td>0.272751</td>\n",
              "      <td>4.321285</td>\n",
              "      <td>1.569835</td>\n",
              "      <td>0.634354</td>\n",
              "      <td>-0.550853</td>\n",
              "      <td>2.161058</td>\n",
              "      <td>-0.459699</td>\n",
              "      <td>0.742737</td>\n",
              "      <td>-0.778183</td>\n",
              "      <td>0.656047</td>\n",
              "      <td>0.445491</td>\n",
              "      <td>1.299726</td>\n",
              "      <td>1.210270</td>\n",
              "      <td>1.080307</td>\n",
              "      <td>1.435914</td>\n",
              "      <td>-0.992491</td>\n",
              "      <td>2.013223</td>\n",
              "      <td>0.410796</td>\n",
              "      <td>-0.387851</td>\n",
              "      <td>-0.697368</td>\n",
              "      <td>-0.624541</td>\n",
              "      <td>1.979515</td>\n",
              "      <td>-0.26531</td>\n",
              "      <td>0.064496</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.659602</td>\n",
              "      <td>0.427319</td>\n",
              "      <td>1.279784</td>\n",
              "      <td>1.255604</td>\n",
              "      <td>1.520442</td>\n",
              "      <td>1.190339</td>\n",
              "      <td>0.864978</td>\n",
              "      <td>0.910992</td>\n",
              "      <td>1.138400</td>\n",
              "      <td>0.634851</td>\n",
              "      <td>-0.124700</td>\n",
              "      <td>-0.579862</td>\n",
              "      <td>1.295523</td>\n",
              "      <td>-0.108997</td>\n",
              "      <td>0.050769</td>\n",
              "      <td>-0.497900</td>\n",
              "      <td>0.743166</td>\n",
              "      <td>1.184591</td>\n",
              "      <td>0.924837</td>\n",
              "      <td>-0.786118</td>\n",
              "      <td>0.072120</td>\n",
              "      <td>1.154462</td>\n",
              "      <td>-0.744500</td>\n",
              "      <td>1.074286</td>\n",
              "      <td>1.596360</td>\n",
              "      <td>-0.873943</td>\n",
              "      <td>0.947234</td>\n",
              "      <td>0.238758</td>\n",
              "      <td>0.357634</td>\n",
              "      <td>-0.306862</td>\n",
              "      <td>1.060050</td>\n",
              "      <td>-0.236844</td>\n",
              "      <td>-0.26531</td>\n",
              "      <td>0.546826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>-1.396816</td>\n",
              "      <td>-0.485352</td>\n",
              "      <td>0.625359</td>\n",
              "      <td>0.504764</td>\n",
              "      <td>-0.261098</td>\n",
              "      <td>-0.352752</td>\n",
              "      <td>1.417640</td>\n",
              "      <td>0.616807</td>\n",
              "      <td>0.402000</td>\n",
              "      <td>-0.639013</td>\n",
              "      <td>-0.381911</td>\n",
              "      <td>0.178510</td>\n",
              "      <td>-0.597169</td>\n",
              "      <td>0.566762</td>\n",
              "      <td>0.631586</td>\n",
              "      <td>-0.497900</td>\n",
              "      <td>-0.459699</td>\n",
              "      <td>0.237092</td>\n",
              "      <td>0.345890</td>\n",
              "      <td>-0.786118</td>\n",
              "      <td>-0.630285</td>\n",
              "      <td>0.776386</td>\n",
              "      <td>0.744373</td>\n",
              "      <td>-0.374436</td>\n",
              "      <td>0.329600</td>\n",
              "      <td>-0.386987</td>\n",
              "      <td>-0.416999</td>\n",
              "      <td>0.112814</td>\n",
              "      <td>-0.387851</td>\n",
              "      <td>-0.697368</td>\n",
              "      <td>0.031788</td>\n",
              "      <td>-0.732879</td>\n",
              "      <td>-0.26531</td>\n",
              "      <td>0.862344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1.799861</td>\n",
              "      <td>1.150422</td>\n",
              "      <td>0.654544</td>\n",
              "      <td>1.012722</td>\n",
              "      <td>0.363497</td>\n",
              "      <td>1.149256</td>\n",
              "      <td>1.256522</td>\n",
              "      <td>0.459767</td>\n",
              "      <td>1.019238</td>\n",
              "      <td>-0.291694</td>\n",
              "      <td>2.270498</td>\n",
              "      <td>1.735677</td>\n",
              "      <td>0.931907</td>\n",
              "      <td>1.802715</td>\n",
              "      <td>-0.550853</td>\n",
              "      <td>-0.497900</td>\n",
              "      <td>-0.459699</td>\n",
              "      <td>-3.741549</td>\n",
              "      <td>-0.778183</td>\n",
              "      <td>-0.786118</td>\n",
              "      <td>1.101045</td>\n",
              "      <td>1.279933</td>\n",
              "      <td>0.807132</td>\n",
              "      <td>1.823290</td>\n",
              "      <td>1.543040</td>\n",
              "      <td>0.673735</td>\n",
              "      <td>-0.416999</td>\n",
              "      <td>0.917741</td>\n",
              "      <td>0.065323</td>\n",
              "      <td>-0.697368</td>\n",
              "      <td>1.549627</td>\n",
              "      <td>-0.732879</td>\n",
              "      <td>-0.26531</td>\n",
              "      <td>-3.492455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1.166063</td>\n",
              "      <td>-0.277376</td>\n",
              "      <td>0.547420</td>\n",
              "      <td>0.546770</td>\n",
              "      <td>-0.232914</td>\n",
              "      <td>-1.405149</td>\n",
              "      <td>-0.732767</td>\n",
              "      <td>0.166671</td>\n",
              "      <td>-0.327599</td>\n",
              "      <td>0.354038</td>\n",
              "      <td>-0.319064</td>\n",
              "      <td>0.331496</td>\n",
              "      <td>1.022024</td>\n",
              "      <td>-1.623367</td>\n",
              "      <td>-0.550853</td>\n",
              "      <td>0.031693</td>\n",
              "      <td>0.827035</td>\n",
              "      <td>0.173805</td>\n",
              "      <td>-0.778183</td>\n",
              "      <td>-0.786118</td>\n",
              "      <td>0.707982</td>\n",
              "      <td>0.069510</td>\n",
              "      <td>-1.401472</td>\n",
              "      <td>0.077694</td>\n",
              "      <td>0.781131</td>\n",
              "      <td>1.022201</td>\n",
              "      <td>-0.416999</td>\n",
              "      <td>0.666394</td>\n",
              "      <td>-0.387851</td>\n",
              "      <td>-0.697368</td>\n",
              "      <td>1.976239</td>\n",
              "      <td>-0.732879</td>\n",
              "      <td>-0.26531</td>\n",
              "      <td>0.418635</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       CD45  CD196_CCR6  CD181_CXCR1  ...  CD279_PD1     CD56      CD16\n",
              "0 -0.279450   -0.707366     0.384317  ...   1.979515 -0.26531  0.064496\n",
              "3  0.659602    0.427319     1.279784  ...  -0.236844 -0.26531  0.546826\n",
              "5 -1.396816   -0.485352     0.625359  ...  -0.732879 -0.26531  0.862344\n",
              "6  1.799861    1.150422     0.654544  ...  -0.732879 -0.26531 -3.492455\n",
              "7  1.166063   -0.277376     0.547420  ...  -0.732879 -0.26531  0.418635\n",
              "\n",
              "[5 rows x 34 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asvcNjTREVS5",
        "outputId": "ec029d55-4e09-43a1-8b6b-63a730e9df95"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 34)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gX2LqxWjFQYP"
      },
      "source": [
        "map = {}\n",
        "\n",
        "for protein in data:\n",
        "  for value in data[protein]:\n",
        "    if protein not in map:\n",
        "      map[protein] = set()\n",
        "    map[protein].add(value)\n",
        "    if len(map[protein]) == 2:\n",
        "      break\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8LUF9PsJZN3",
        "outputId": "ad1afcac-bb38-4098-b1e8-9b88d2daeb70"
      },
      "source": [
        "l = []\n",
        "\n",
        "for key in map:\n",
        "  l.append(map[key])\n",
        "l"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{-0.27945008873939514, 0.6596015691757202},\n",
              " {-0.707366406917572, 0.42731931805610657},\n",
              " {0.384317010641098, 1.2797837257385254},\n",
              " {0.8369234204292297, 1.2556043863296509},\n",
              " {1.0969451665878296, 1.5204423666000366},\n",
              " {0.2288081794977188, 1.1903390884399414},\n",
              " {-0.09654375910758972, 0.8649781346321106},\n",
              " {0.7672399282455444, 0.9109917283058167},\n",
              " {0.8201862573623657, 1.1384004354476929},\n",
              " {0.6348510384559631, 0.6658516526222229},\n",
              " {-0.12469985336065292, 0.272750586271286},\n",
              " {-0.5798620581626892, 4.321284770965576},\n",
              " {1.2955232858657837, 1.569834589958191},\n",
              " {-0.10899665951728821, 0.6343538165092468},\n",
              " {-0.5508525371551514, 0.050768833607435226},\n",
              " {-0.49790024757385254, 2.161057710647583},\n",
              " {-0.4596991240978241, 0.7431658506393433},\n",
              " {0.7427371740341187, 1.1845905780792236},\n",
              " {-0.7781826257705688, 0.9248367547988892},\n",
              " {-0.7861180305480957, 0.6560471057891846},\n",
              " {0.07212047278881073, 0.4454909563064575},\n",
              " {1.1544617414474487, 1.2997262477874756},\n",
              " {-0.7445002198219299, 1.2102696895599365},\n",
              " {1.0742855072021484, 1.080306887626648},\n",
              " {1.435914158821106, 1.5963603258132935},\n",
              " {-0.9924909472465515, -0.873943030834198},\n",
              " {0.9472337365150452, 2.0132226943969727},\n",
              " {0.2387584000825882, 0.4107963740825653},\n",
              " {-0.3878510892391205, 0.3576340675354004},\n",
              " {-0.6973678469657898, -0.30686214566230774},\n",
              " {-0.6245408058166504, 1.060050129890442},\n",
              " {-0.2368435561656952, 1.9795148372650146},\n",
              " {-0.2653104364871979, 0.3934451639652252},\n",
              " {0.0644955262541771, 0.5468258857727051}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dH5T-q50Tre"
      },
      "source": [
        "def getProtein(value):\n",
        "  for key in map:\n",
        "    if value in map[key]:\n",
        "      return key\n",
        "\n",
        "def getSuffix(protein, value):\n",
        "  if max(map[protein]) - value == 0:\n",
        "    return '+'\n",
        "  else:\n",
        "    return '-'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYt6mADUKUST"
      },
      "source": [
        "def split_dataframe(df, chunk_size = 1000000): \n",
        "    chunks = list()\n",
        "    num_chunks = len(df) // chunk_size + 1\n",
        "    for i in range(num_chunks):\n",
        "        chunks.append(df[i*chunk_size:(i+1)*chunk_size])\n",
        "    return chunks\n",
        "\n",
        "data = split_dataframe(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9gh8WROKZm2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20c38499-e23e-48d7-df08-697ab339cf60"
      },
      "source": [
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[         CD45  CD196_CCR6  CD181_CXCR1  ...  CD279_PD1      CD56      CD16\n",
              " 0   -0.279450   -0.707366     0.384317  ...   1.979515 -0.265310  0.064496\n",
              " 3    0.659602    0.427319     1.279784  ...  -0.236844 -0.265310  0.546826\n",
              " 5   -1.396816   -0.485352     0.625359  ...  -0.732879 -0.265310  0.862344\n",
              " 6    1.799861    1.150422     0.654544  ...  -0.732879 -0.265310 -3.492455\n",
              " 7    1.166063   -0.277376     0.547420  ...  -0.732879 -0.265310  0.418635\n",
              " ..        ...         ...          ...  ...        ...       ...       ...\n",
              " 128  0.516790   -0.707366    -0.021224  ...  -0.732879 -0.265310  0.114201\n",
              " 129  0.211735   -0.707366     1.809287  ...  -0.732879 -0.265310 -1.042863\n",
              " 130 -1.303168   -0.707366    -1.153692  ...  -0.732879 -0.265310  0.306272\n",
              " 131 -0.393257    0.144885    -1.153692  ...  -0.732879 -0.265310 -0.168588\n",
              " 133  0.451776   -0.707366     0.861812  ...  -0.732879  2.955293  0.375529\n",
              " \n",
              " [100 rows x 34 columns]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "id": "XiUFzxnBJdHC",
        "outputId": "e34b7be5-865f-4044-c4b1-1dd303c7d822"
      },
      "source": [
        "def getText( x ):\n",
        "    protein_names = []\n",
        "    for i,protein_value in enumerate(x):\n",
        "      protein = getProtein(protein_value)\n",
        "      suffix = getSuffix(protein, protein_value)\n",
        "\n",
        "      protein_names.append(protein + suffix)\n",
        "\n",
        "    return ' '.join(protein_names)\n",
        "\n",
        "for index,chunk in enumerate(data):\n",
        "  text_representation = np.apply_along_axis( getText, axis=1, arr=chunk)\n",
        "\n",
        "  with open(f'preprocessed_cell_corpus_{index}.txt', 'w') as file:\n",
        "    for line in text_representation:\n",
        "      file.write(f'{line}\\n')\n",
        "  print(f'done chunk {index}')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-064c7b763e65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m   \u001b[0mtext_representation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_along_axis\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mgetText\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'preprocessed_cell_corpus_{index}.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mapply_along_axis\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/lib/shape_base.py\u001b[0m in \u001b[0;36mapply_along_axis\u001b[0;34m(func1d, axis, arr, *args, **kwargs)\u001b[0m\n\u001b[1;32m    400\u001b[0m     \u001b[0mbuff\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m         \u001b[0mbuff\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minarr_view\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-064c7b763e65>\u001b[0m in \u001b[0;36mgetText\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprotein_value\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m       \u001b[0mprotein\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetProtein\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotein_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m       \u001b[0msuffix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetSuffix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotein\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotein_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m       \u001b[0mprotein_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotein\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-5dcbc789ef38>\u001b[0m in \u001b[0;36mgetSuffix\u001b[0;34m(protein, value)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgetSuffix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotein\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprotein\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m'+'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: None"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "RMIeYiOIzgWf",
        "outputId": "cadf6fe6-65b8-4bd1-d4ad-a616ec4958dc"
      },
      "source": [
        "text_representation"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-93bfd6b1149b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtext_representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'text_representation' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "Qj5Yp_MH3OLL",
        "outputId": "cb66a70d-755b-40b3-e03b-8946d90e7cc8"
      },
      "source": [
        "text_representation"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-93bfd6b1149b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtext_representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'text_representation' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wurB7oMpAPh"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iJekoKc7P7h",
        "outputId": "8c9f6b4f-7515-42a8-84f5-1e33ee894694"
      },
      "source": [
        "!pip install tokenizers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.7/dist-packages (0.10.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNEiywff0DT_",
        "outputId": "5862c1bc-dc3f-46e8-ebc6-fc638a6f35c5"
      },
      "source": [
        "!gsutil cp gs://cytereader/preprocessed_cell_corpus_0.txt . \n",
        "!gsutil cp gs://cytereader/preprocessed_cell_corpus_1.txt . "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://cytereader/preprocessed_cell_corpus_0.txt...\n",
            "\\ [1 files][267.0 MiB/267.0 MiB]                                                \n",
            "Operation completed over 1 objects/267.0 MiB.                                    \n",
            "Copying gs://cytereader/preprocessed_cell_corpus_1.txt...\n",
            "\\ [1 files][267.0 MiB/267.0 MiB]                                                \n",
            "Operation completed over 1 objects/267.0 MiB.                                    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9XXbbzWpCRi",
        "outputId": "9366f8d8-6ef7-4e15-db3c-40628efa1fa3"
      },
      "source": [
        "from tokenizers import BertWordPieceTokenizer\n",
        "\n",
        "wb_tokenizer = BertWordPieceTokenizer(clean_text=True,\n",
        "                                      strip_accents=True, lowercase=False)\n",
        "\n",
        "wb_tokenizer.train(['preprocessed_cell_corpus_0.txt', 'preprocessed_cell_corpus_1.txt'],\n",
        "                   vocab_size=10000, min_frequency=2,\n",
        "                   special_tokens=[\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"])\n",
        "wb_tokenizer.save_model(\".\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['./vocab.txt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EsROp3Se1QeA",
        "outputId": "b1232316-41c0-4a89-efd6-13926ef5b808"
      },
      "source": [
        "from transformers import RobertaConfig, RobertaTokenizer, RobertaModel, RobertaForMaskedLM\n",
        "\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-large')\n",
        "configuration = RobertaConfig(vocab_size=1000)\n",
        "\n",
        "\n",
        "model = RobertaForMaskedLM(configuration)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading file https://huggingface.co/roberta-large/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/7c1ba2435b05451bc3b4da073c8dec9630b22024a65f6c41053caccf2880eb8f.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n",
            "loading file https://huggingface.co/roberta-large/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/20b5a00a80e27ae9accbe25672aba42ad2d4d4cb2c4b9359b50ca8e34e107d6d.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
            "loading file https://huggingface.co/roberta-large/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/roberta-large/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/roberta-large/resolve/main/tokenizer_config.json from cache at None\n",
            "loading file https://huggingface.co/roberta-large/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/e16a2590deb9e6d73711d6e05bf27d832fa8c1162d807222e043ca650a556964.fc9576039592f026ad76a1c231b89aee8668488c671dfbe6616bab2ed298d730\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zo006Ohb7Odq",
        "outputId": "87b1923e-c33f-4ab1-d76c-b39f8fd76b51"
      },
      "source": [
        "model.num_parameters()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "86811880"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27tNvSbD1i0Z",
        "outputId": "0f9fbe09-1a32-4c39-b186-62db979758c9"
      },
      "source": [
        "%%time\n",
        "from transformers import LineByLineTextDataset\n",
        "\n",
        "dataset = LineByLineTextDataset(\n",
        "    tokenizer=tokenizer,\n",
        "    file_path=\"preprocessed_cell_corpus_0.txt\",\n",
        "    block_size=128,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/data/datasets/language_modeling.py:124: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/pytorch/language-modeling/run_mlm.py\n",
            "  FutureWarning,\n",
            "Creating features from dataset file at preprocessed_cell_corpus_0.txt\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 10min 25s, sys: 23.3 s, total: 10min 48s\n",
            "Wall time: 10min 48s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDvACIyx2l73"
      },
      "source": [
        "from transformers import DataCollatorForLanguageModeling\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fn_oz7tu9Q13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af61ace2-4aa9-484d-ab65-cf8d5f9e4dcb"
      },
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./cellAttention\",\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=64,\n",
        "    save_steps=10_000,\n",
        "    save_total_limit=2,\n",
        "    prediction_loss_only=True,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=dataset,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "-_mKjdOV9UF8",
        "outputId": "3bed746b-ea43-4f65-912b-38ae651c1f26"
      },
      "source": [
        "# %%time\n",
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 1000000\n",
            "  Num Epochs = 1\n",
            "  Instantaneous batch size per device = 64\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 15625\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-068f9f09d0d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# %%time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, **kwargs)\u001b[0m\n\u001b[1;32m   1267\u001b[0m                         \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1269\u001b[0;31m                     \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1270\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_flos\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloating_point_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   1760\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1762\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_gpu\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   1792\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1793\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1794\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1795\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1796\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: forward() got an unexpected keyword argument 'labels'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNfsthQO9WYk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d543e07-c603-4aae-de10-a22307fb3a58"
      },
      "source": [
        "trainer.save_model(\"./cellAttention\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to ./cellAttention\n",
            "Configuration saved in ./cellAttention/config.json\n",
            "Model weights saved in ./cellAttention/pytorch_model.bin\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KaQacVClEQP8",
        "outputId": "df389687-7f9e-4875-f8ba-2030ac8b3464"
      },
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "fill_mask = pipeline(\n",
        "    \"fill-mask\",\n",
        "    model=\"./cellAttention\",\n",
        "    tokenizer=\"./cellAttention\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading configuration file ./cellAttention/config.json\n",
            "Model config RobertaConfig {\n",
            "  \"architectures\": [\n",
            "    \"RobertaModel\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.9.0.dev0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 1000\n",
            "}\n",
            "\n",
            "loading configuration file ./cellAttention/config.json\n",
            "Model config RobertaConfig {\n",
            "  \"architectures\": [\n",
            "    \"RobertaModel\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.9.0.dev0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 1000\n",
            "}\n",
            "\n",
            "loading weights file ./cellAttention/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing RobertaForMaskedLM.\n",
            "\n",
            "Some weights of RobertaForMaskedLM were not initialized from the model checkpoint at ./cellAttention and are newly initialized: ['lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
            "loading configuration file ./cellAttention/config.json\n",
            "Model config RobertaConfig {\n",
            "  \"architectures\": [\n",
            "    \"RobertaModel\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.9.0.dev0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 1000\n",
            "}\n",
            "\n",
            "Didn't find file ./cellAttention/vocab.json. We won't load it.\n",
            "Didn't find file ./cellAttention/merges.txt. We won't load it.\n",
            "Didn't find file ./cellAttention/tokenizer.json. We won't load it.\n",
            "Didn't find file ./cellAttention/added_tokens.json. We won't load it.\n",
            "Didn't find file ./cellAttention/special_tokens_map.json. We won't load it.\n",
            "Didn't find file ./cellAttention/tokenizer_config.json. We won't load it.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-a93b5e3aafe7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m\"fill-mask\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"./cellAttention\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"./cellAttention\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/pipelines/__init__.py\u001b[0m in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, framework, revision, use_fast, use_auth_token, model_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m             tokenizer = AutoTokenizer.from_pretrained(\n\u001b[0;32m--> 443\u001b[0;31m                 \u001b[0mtokenizer_identifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_fast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_fast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_from_pipeline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtokenizer_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m             )\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/auto/tokenization_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0mtokenizer_class_py\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer_class_fast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTOKENIZER_MAPPING\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtokenizer_class_fast\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0muse_fast\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtokenizer_class_py\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer_class_fast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtokenizer_class_py\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1706\u001b[0m                 \u001b[0;34mf\"- or '{pretrained_model_name_or_path}' is the correct path to a directory containing relevant tokenizer files\\n\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m             )\n\u001b[0;32m-> 1708\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mEnvironmentError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfile_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvocab_files\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Can't load tokenizer for './cellAttention'. Make sure that:\n\n- './cellAttention' is a correct model identifier listed on 'https://huggingface.co/models'\n\n- or './cellAttention' is the correct path to a directory containing relevant tokenizer files\n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-Cg3tatEZuT"
      },
      "source": [
        "fill_mask(\"CD45+ CD196_CCR6+ CD181_CXCR1- HLA_DR- CD15- CD31_PECAM1- CD8a- CD182_CXCR2[MASK] CD66ace- CD63- CD14- CD66b- CD62L_Lselectin- CD3+ CD27- CD86+ CD10- CD197_CCR7+ CD28- CD11c- CD33- CD161- CD45RO- CD24- CD38+ CD278_ICOS- CD32- CD152_CTLA4+ IgM+ CD184_CXCR4+ CD279_PD1- CD56+ CD16-\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GU-Uqz46FfmS"
      },
      "source": [
        "input = 'CD45+ CD196_CCR6+ CD181_CXCR1- HLA_DR- CD15-'\n",
        "masked_input = 'CD45+ CD196_CCR6+ CD181_CXCR1[MASKED] HLA_DR- CD15-'\n",
        "\n",
        "output = 'CD45+ CD196_CCR6+ CD181_CXCR1-/+ HLA_DR- CD15-'"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}